{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "from pymongo import MongoClient\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import openai\n",
    "import os, pprint\n",
    "from functools import lru_cache\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "load_dotenv()\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "MONGODB_URI = os.getenv('MONGODB_URI')\n",
    "db_name = os.getenv('MONGODB_DATABASE')\n",
    "collection_name = os.getenv('MONGODB_TEMPUSER')\n",
    "vector_search_idx = os.getenv('MONGODB_VECTOR_INDEX_TEMPUSER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(MONGODB_URI)\n",
    "db = client[db_name]\n",
    "collection = db[collection_name]\n",
    "\n",
    "def get_user_embeddings(session_id):\n",
    "    user_doc = collection.find_one({\"session_id\": session_id})\n",
    "    if user_doc and \"embeddings\" in user_doc:\n",
    "        return user_doc[\"embeddings\"]\n",
    "    return None\n",
    "\n",
    "# Assuming 'session_id' is known and valid\n",
    "session_embeddings = get_user_embeddings(\"_HrwNQCNinc_Ki6kMT3vkw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_search = MongoDBAtlasVectorSearch(\n",
    "   embedding=OpenAIEmbeddings(disallowed_special=()),\n",
    "   collection=collection,  # Ensure this collection is correctly set up for vector search\n",
    "   index_name=vector_search_idx,\n",
    "   embedding_key = \"embeddings\"\n",
    ")\n",
    "\n",
    "retriever = vector_search.as_retriever(\n",
    "   search_type=\"similarity\",\n",
    "   search_kwargs={\"k\": 5, \"score_threshold\": 0.75}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer or if it is not provided in the context, just say that you don't know, don't try to make up an answer.\n",
    "If the answer is in the context, don't say mentioned in the context.\n",
    "Please provide a detailed explanation and if applicable, give examples or historical context.\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "def format_docs(docs):\n",
    "   return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "   {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "   | custom_rag_prompt\n",
    "   | llm\n",
    "   | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mCache Info: CacheInfo(hits=0, misses=1, maxsize=100, currsize=1)\u001b[0m\n",
      "\u001b[91mQuestion: What's my name?\u001b[0m\n",
      "\u001b[92mAnswer: I'm sorry, but without any information provided about your name in the context, I don't know what your name is.\u001b[0m\n",
      "\n",
      "Source documents:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "MAX_CACHE_SIZE = 100\n",
    "@lru_cache(maxsize=MAX_CACHE_SIZE)\n",
    "def cached_query(question):\n",
    "    response = rag_chain.invoke(question)\n",
    "    return response\n",
    "\n",
    "RED = '\\033[91m'\n",
    "GREEN = '\\033[92m'\n",
    "YELLOW = '\\033[93m'\n",
    "RESET = '\\033[0m'\n",
    "\n",
    "\n",
    "question = \"What's my name?\"\n",
    "answer = cached_query(question) \n",
    "\n",
    "print(f\"{YELLOW}Cache Info: {cached_query.cache_info()}{RESET}\")\n",
    "print(f\"{RED}Question: {question}{RESET}\")\n",
    "print(f\"{GREEN}Answer: {answer}{RESET}\")\n",
    "\n",
    "documents = retriever.get_relevant_documents(question)\n",
    "print(\"\\nSource documents:\")\n",
    "pprint.pprint(documents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
