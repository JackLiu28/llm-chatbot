{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG Pipeline Test with MongoDB Vector Store </br>\n",
    "Author: Sanjit Verma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from pymongo import MongoClient\n",
    "import logging\n",
    "import os, pprint\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from functools import lru_cache\n",
    "\n",
    "load_dotenv()\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "MONGODB_URI = os.getenv('MONGODB_URI')\n",
    "db_name = os.getenv('MONGODB_DATABASE')\n",
    "collection_name = os.getenv('MONGODB_VECTORS')\n",
    "vector_search_idx = os.getenv('MONGODB_VECTOR_INDEX')\n",
    "openai.api_key = OPENAI_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to db\n",
    "client = MongoClient(MONGODB_URI)\n",
    "db = client[db_name]\n",
    "collection = db[collection_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_search = MongoDBAtlasVectorSearch( # retrieve documents from MongoDB collection\n",
    "   embedding=OpenAIEmbeddings(disallowed_special=()),\n",
    "   collection=collection,\n",
    "   index_name=vector_search_idx,\n",
    ")\n",
    "\n",
    "retriever = vector_search.as_retriever( #This method configures the vector_search instance to retrieve documents based on similarity.\n",
    "   search_type = \"similarity\",\n",
    "   search_kwargs = {\"k\": 5, \"score_threshold\": 0.75} # top 10 most similar documents, , only return documents with a similarity score of 0.75 or higher \n",
    ")\n",
    "\n",
    "#Define the template used to format the input for the language model and provide a consistent response\n",
    "template = \"\"\"\n",
    "Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer or if it is not provided in the context, just say that you don't know, don't try to make up an answer.\n",
    "If the answer is in the context, dont say mentioned in the context.\n",
    "Please provide a detailed explanation and if applicable, give examples or historical context.\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "def format_docs(docs):\n",
    "   return \"\\n\\n\".join(doc.page_content for doc in docs) # This function formats the documents retrieved from MongoDB into a single string with each document separated by two newlines. \n",
    "\n",
    "rag_chain = (\n",
    "   # retriever first gets all relevant documents, then that is passed to the next step in the chain which is formatting docs (denoted by |)\n",
    "   { \"context\": retriever | format_docs, \"question\": RunnablePassthrough()} #runnable passthrough is used to pass the question to the next step in the chain without mods\n",
    "   | custom_rag_prompt\n",
    "   | llm\n",
    "   | StrOutputParser()\n",
    ")\n",
    "\n",
    "# demonstrating caching of mongoDB queries + questions, very basic example actual \n",
    "MAX_CACHE_SIZE = 100\n",
    "@lru_cache(maxsize=MAX_CACHE_SIZE)\n",
    "def cached_query(question):\n",
    "    response = rag_chain.invoke(question)\n",
    "    return response\n",
    "\n",
    "RED = '\\033[91m'\n",
    "GREEN = '\\033[92m'\n",
    "YELLOW = '\\033[93m'\n",
    "RESET = '\\033[0m'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mCache Info: CacheInfo(hits=5, misses=3, maxsize=100, currsize=3)\u001b[0m\n",
      "\u001b[91mQuestion: Who grew up in California, and for fun he enters sporting events\u001b[0m\n",
      "\u001b[92mAnswer: Answer: David Patterson\u001b[0m\n",
      "\n",
      "Source documents:\n",
      "[Document(page_content='ing Academic Alumni Award. He grew up in California, and for fun he enters sporting events\\nwith his two adult sons, including weekly soccer games and charity bike rides.\\ni', metadata={'_id': {'$oid': '667098a093f1f75cc12859b9'}, 'source': '/Users/sanjitverma/git/TAChatBot/saas-backend/pdfData/textbook.pdf', 'page': 2}),\n",
      " Document(page_content='his UC Berkeley dissertation research on mobile computing including the world’s ﬁrst mo-\\nbile graphical web browser (Top Gun Wingman on Palm Pilot), and co-founded a couple of\\nstartups that were artistic successes. He received his BS in electrical engineering and com-\\nputer science from MIT and his MS from the University of Illinois at Urbana-Champaign.\\nHe is also a classically-trained musician, freelance Music Director, and bilingual/bicultural\\n(Cuban-American) New Yorker transplanted to San Francisco.\\nDavid Patterson (pronouns: he, him) recently retired from a 40-year career as a Professor of\\nComputer Science at UC Berkeley. In the past, he served as Chair of Berkeley’s Computer\\nScience Division, Chair of the Computing Research Association, and President of the Asso-\\nciation for Computing Machinery. His best-known research projects are Reduced Instruction\\nSet Computers (RISC), Redundant Arrays of Inexpensive Disks (RAID), and Networks of\\nWorkstations (NOW). This research led to many papers, 6 books, and more than 35 hon-', metadata={'_id': {'$oid': '667098a093f1f75cc12859b7'}, 'source': '/Users/sanjitverma/git/TAChatBot/saas-backend/pdfData/textbook.pdf', 'page': 2}),\n",
      " Document(page_content='ii', metadata={'_id': {'$oid': '667098a093f1f75cc12859ba'}, 'source': '/Users/sanjitverma/git/TAChatBot/saas-backend/pdfData/textbook.pdf', 'page': 3}),\n",
      " Document(page_content='4', metadata={'_id': {'$oid': '667098a093f1f75cc1285f7d'}, 'source': '/Users/sanjitverma/git/TAChatBot/saas-backend/pdfData/midterm practice solutions.pdf', 'page': 3}),\n",
      " Document(page_content='January 2021\\nSan Francisco, California\\nNotes\\n1http://www.saasbook.info/welcome-1st-edition\\n2http://www.saasbook.info\\n3https://codio.com/esaas', metadata={'_id': {'$oid': '667098a093f1f75cc12859d4'}, 'source': '/Users/sanjitverma/git/TAChatBot/saas-backend/pdfData/textbook.pdf', 'page': 11})]\n"
     ]
    }
   ],
   "source": [
    "question = \"Who grew up in California, and for fun he enters sporting events\"\n",
    "answer = cached_query(question) # convert question to embedding and he most relevant documents based on the query's embedding are fetched from the MongoDB collection \n",
    "\n",
    "\n",
    "print(f\"{YELLOW}Cache Info: {cached_query.cache_info()}{RESET}\")\n",
    "print(f\"{RED}Question: {question}{RESET}\")\n",
    "print(f\"{GREEN}Answer: {answer}{RESET}\")\n",
    "\n",
    "documents = retriever.get_relevant_documents(question)\n",
    "print(\"\\nSource documents:\")\n",
    "pprint.pprint(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "STEPS THAT OCCUR IN THE BACKGROUND when .invoke() is called on the rag_chain instance \n",
    "\n",
    "Step 1 INVOCATION: Invocation of rag chain with the question. Method call triggers the chains operation starting with the retriever\n",
    "\n",
    "Step 2 RETRIEVER FUNC: The retriever retrieves the most relevant documents from the MongoDB collection based on the question. Converts question into embedding and \n",
    "uses this to perform a similarity search in the database, retrieving documents that are contextually similar to the query.\n",
    "\n",
    "Step 3 DOC FORMATTING: The retrieved documents are passed to the next step in the chain, which is the format_docs function. This function formats the documents \n",
    "into a single string with each document separated by double newlines (basically processing output from retriever)\n",
    "\n",
    "Step 4 CONTEXT ASSEMBLY: The formatted documents and the question are passed to the custom_rag_prompt function to from complete context. RunnablePassthrough \n",
    "is highly important here to make sure no mods occur to question. \n",
    "\n",
    "Step 5 PROMPT TEMPLATE: template recieves step 4 and fills it out where context is replaced by the output from format_docs and question is replaced by the output from RunnablePasst\n",
    "\n",
    "Step 6 LANGUAGE MODEL: templated string are passed to the language model, which generates a response based on the input.model generates a response based on the input prompt, \n",
    "considering the provided context and directly addressing the query.\n",
    "\n",
    "Step 7 POST PARSE: Takes output and converts it into a string. If it is already a string, return it otherwise if it is a structured object, convert it to a string.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
